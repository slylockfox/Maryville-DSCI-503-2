{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d061fb5-ec6c-46f9-ae93-c51f8bfd78c9",
   "metadata": {},
   "source": [
    "# DSCI 503 - Homework 04\n",
    "### Matt Snyder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "261a184c-4953-4885-be6e-ef57758a8632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1749263-1756-44ce-a855-552fed539dd5",
   "metadata": {},
   "source": [
    "## Problem 1: Sample Mean and Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28c4eb74-7cd5-48b6-bb73-95f1dc3ce14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Mean:     16.6  \n",
      "Sample Variance: 25.6  \n"
     ]
    }
   ],
   "source": [
    "# Create an array x containing the following integers: 10, 16, 26, 12, 17, 22, 14, 12, 21, 16\n",
    "x = np.array([10, 16, 26, 12, 17, 22, 14, 12, 21, 16])\n",
    "\n",
    "# Store the length of this array in a variable n.\n",
    "n = len(x)\n",
    "\n",
    "# Calculate the sample mean, storing the result in mean. You may use np.sum() in your calculation.\n",
    "mean = np.sum(x)/n\n",
    "\n",
    "# Calculate an array named diff that stores the differences between each value in x and the mean. That is to\n",
    "# that that diff should contain values (𝑥𝑖− 𝑥̅) for each𝑖 = 1, . . . , 𝑛.\n",
    "diff = x - mean\n",
    "\n",
    "# Use diff, n, and np.sum() to find the sample variance. Store the result in a variable named var.\n",
    "var = np.sum(diff**2) / (n-1)\n",
    "\n",
    "# Print your results in the format shown below. Make sure that the numerical outputs are aligned with each other\n",
    "print (f'Sample Mean:     {mean:<6}')\n",
    "print (f'Sample Variance: {var:<6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffa0a9d1-abf9-402f-a0ce-00be6a3026d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Mean:     16.6  \n",
      "Sample Variance: 25.6  \n"
     ]
    }
   ],
   "source": [
    "# Use the functions np.mean() and np.var() to calculate the sample mean and sample variance of x, storing the result in\n",
    "# variables named mean_np and var_np. In order to get the sample variance (as opposed to the population variance) you\n",
    "# will need to set the ddof parameter of np.var() to 1.\n",
    "mean_np = np.mean(x)\n",
    "var_np = np.var(x, ddof=1)\n",
    "\n",
    "# Print the results in the same format as above\n",
    "print (f'Sample Mean:     {mean:<6}')\n",
    "print (f'Sample Variance: {var:<6}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d4d1c1-b800-4267-a097-fe0679e9b6b2",
   "metadata": {},
   "source": [
    "## Problem 2: Scoring a Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4299954d-24f9-4542-9fe5-8d976fd2224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sse(true_y, pred_y):\n",
    "    \"\"\" The parameter true_y is expected to be an array of observed 𝑦 values \n",
    "        while pred_y is expected to be an array of predicted 𝑦 values generated by a regression model. \n",
    "        Returns the SSE score for the regression model\n",
    "    \"\"\"\n",
    "    result = np.sum((true_y - pred_y)**2)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eaf22b97-c972-4f5d-8d9e-590def782ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 SSE: 22.66 \n",
      "Model 1 SSE: 19.90 \n"
     ]
    }
   ],
   "source": [
    "# define numpy arrays true_y, pred_1, and pred_2\n",
    "true_y = np.array([22.1, 17.9, 16.5, 14.3, 19.8, 23.7, 22.0, 18.4, 25.7, 19.2])\n",
    "pred_1 = np.array([21.4, 16.7, 17.9, 12.1, 22.1, 25.1, 21.7, 19.3, 23.4, 19.9])\n",
    "pred_2 = np.array([20.7, 18.1, 16.9, 13.6, 21.9, 24.8, 20.3, 21.1, 24.8, 18.4])\n",
    "\n",
    "# Use find_sse() to calculate the SSE score for each model, storing the results in variables named sse_1 and sse_2.\n",
    "sse_1 = find_sse(true_y, pred_1)\n",
    "sse_2 = find_sse(true_y, pred_2)\n",
    "\n",
    "#Print your results in the format shown below. Round your numerical outputs to 2 decimal places.\n",
    "print (f'Model 1 SSE: {sse_1:<6.2f}')\n",
    "print (f'Model 1 SSE: {sse_2:<6.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e2a0ea-e393-4aed-9b75-34c5f8088ffa",
   "metadata": {},
   "source": [
    "## Problem 3: Scoring a Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "979dfe1c-ec78-45ed-9f96-324e48c22c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_accuracy(true_y, pred_y):\n",
    "    \"\"\" The parameter true_y is expected to be an array of observed classes \n",
    "        pred_y is expected to be an array of predicted classes generated by a classification model. \n",
    "        The function returns the accuracy score for the classification model, as calculated on this set of observations. \n",
    "    \"\"\"\n",
    "    result = np.sum(true_y == pred_y) / len(true_y)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "baf75371-925d-4ba0-abd5-892e56e761f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Create arrays named true_diag and pred_diag to store the diagnosis information provided above. \n",
    "true_diag = np.array(['P', 'P', 'N', 'N', 'P', 'N', 'N', 'N', 'P', 'N', 'N', 'N', 'N', 'P', 'P', 'N', 'N',\n",
    "'N', 'N', 'N'])\n",
    "pred_diag = np.array(['N', 'P', 'N', 'P', 'P', 'N', 'P', 'N', 'P', 'N', 'N', 'N', 'P', 'P', 'P', 'N', 'N',\n",
    "'N', 'P', 'N'])\n",
    "\n",
    "# Use find_accuracy() to calculate the accuracy of the classification model that generated these these predictions. \n",
    "accuracy = find_accuracy(true_diag, pred_diag)\n",
    "\n",
    "# print the result in the following format:\n",
    "print (f'Model Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25db5f2d-a0c8-4db1-bd12-3b8bdb388099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "# Create arrays named true_labels and pred_labels to store the label information provided above. \n",
    "true_labels = np.array(['dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat',\n",
    "'cat', 'dog', 'dog', 'dog', 'dog', 'cat', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat'])\n",
    "pred_labels = np.array(['dog', 'dog', 'cat', 'dog', 'cat', 'dog', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat',\n",
    "'cat', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'dog', 'dog', 'cat', 'cat'])\n",
    "\n",
    "# Use find_accuracy() to calculate the accuracy of the classification model that generated these these predictions. \n",
    "accuracy = find_accuracy(true_labels, pred_labels)\n",
    "\n",
    "# print the result in the following format:\n",
    "print (f'Model Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14a1f06-1c93-468f-ad5f-5cdbf6d3b247",
   "metadata": {},
   "source": [
    "## Problem 4: Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "747dd52e-b240-42f5-bbd3-21730e80e3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report(true_y, pred_y):\n",
    "    \"\"\" This function will print several metrics used to evaluation the performance of a classification model \n",
    "        based on the supplied values of true_y and pred_y. \n",
    "    \"\"\"\n",
    "    # Create a local variable called classes that stores the unique values that appear in true_y. \n",
    "    # value in classes[0] is the \"negative class\" and the value in classes[1] is the \"positive class\".\n",
    "    classes = np.unique(true_y)\n",
    "    \n",
    "    # Use find_accuracy() to calculate and store the model's accuracy.\n",
    "    accuracy = find_accuracy(true_y, pred_y)\n",
    "    \n",
    "    # Use NumPy (and no loops) to calculate TP, FP, TN, and FN.\n",
    "    # TP if it was predicted to be in the positive class, and actually was in the positive class.\n",
    "    TP = np.sum((pred_y == classes[0]) & (true_y == classes[0]))\n",
    "    # FP if it was predicted to be in the positive class, but actually was in the negative class.\n",
    "    FP = np.sum((pred_y == classes[0]) & (true_y == classes[1]))\n",
    "    # TN if it was predicted to be in the negative class, and actually was in the negative class.\n",
    "    TN = np.sum((pred_y == classes[1]) & (true_y == classes[1]))\n",
    "    # FN if it was predicted to be in the negative class, but actually was in the positive class.\n",
    "    FN = np.sum((pred_y == classes[1]) & (true_y == classes[0]))\n",
    "\n",
    "    #Calculate the positive precision, positive recall, negative precision, and negative recall.\n",
    "\n",
    "    positive_precision = TP / (TP + FP)\n",
    "    positive_recall = TP / (TP + FN)\n",
    "    negative_precision = TN / (TN + FN)\n",
    "    negative_recall = TN / (TN + FP)\n",
    "\n",
    "    # Print several lines displaying the results of these calculations, as shown below. \n",
    "    print ('Positive Class:     ' + classes[0])\n",
    "    print ('Negative Class:     ' + classes[1])\n",
    "    print()\n",
    "    print (f'Accuracy:           {accuracy:<6.4f}')\n",
    "    print (f'Positive Precision: {positive_precision:<6.4f}')\n",
    "    print (f'Positive Recall:    {positive_recall:<6.4f}')\n",
    "    print (f'Negative Precision: {negative_precision:<6.4f}')\n",
    "    print (f'Negative Recall:    {negative_recall:<6.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6592760a-caac-46f9-9dc3-41c9a1d54dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Class:     N\n",
      "Negative Class:     P\n",
      "\n",
      "Accuracy:           0.7500\n",
      "Positive Precision: 0.9091\n",
      "Positive Recall:    0.7143\n",
      "Negative Precision: 0.5556\n",
      "Negative Recall:    0.8333\n"
     ]
    }
   ],
   "source": [
    "# Use the classification_report() function to display a report for the medical diagnosis model from Problem 3.\n",
    "classification_report(true_diag, pred_diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ace1c99d-0f1f-4ddc-8d82-3f470323202d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Class:     cat\n",
      "Negative Class:     dog\n",
      "\n",
      "Accuracy:           0.8750\n",
      "Positive Precision: 0.9167\n",
      "Positive Recall:    0.8462\n",
      "Negative Precision: 0.8333\n",
      "Negative Recall:    0.9091\n"
     ]
    }
   ],
   "source": [
    "# Use the classification_report() function to display a report for the image classification model from Problem 3.\n",
    "classification_report(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3f2672-c42b-48a9-98f8-4d06585be02d",
   "metadata": {},
   "source": [
    "## Problem 5: Transformation of Random Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a84a183-0977-402e-925a-b4b094cc13ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use numpy to set a seed of 1. Use np.random.normal to sample 25,000 observations from a normal distribution with a\n",
    "# mean of 0 and a standard deviation of 0.4. Name the resulting array X \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dd128f-414c-4e43-bfc4-535ad65ba214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29361084-302b-44bc-a2fc-1ee0c1e6a97a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64fbc6e-4780-4a2e-bd45-d590c8bfc7d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fb4e33-227b-41da-833e-9715f5bf7a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875afb66-92a2-49a8-9e9e-9a867a9f1a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f05afb-0190-4064-8ea4-c51c92ef8761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4967cff5-83ad-41e3-93ed-d11fdf28520f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988e4638-25e0-4c30-a60a-e8594910b329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbdf0d7-3dc7-4a57-82cc-acbfbb7e92da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbe71aa-8bcf-4088-ab49-a6e918b5fab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becf1c2a-145a-4a3b-8653-88f8714bfda6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f88d2c5-9e3e-4b72-bc5d-19a12eee6dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a38007-c992-4815-a620-90dbca5e832f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2f13ca-f2f7-416e-9050-3a18729d3d54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110ac31c-6ad4-435a-90a9-95565f2f42ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
